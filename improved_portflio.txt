<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Portfolio with 3D Eye</title>
<style>
  body, html {
    margin: 0;
    padding: 0;
    overflow: hidden;
    background: #0a0a0a;
    font-family: Arial, sans-serif;
    color: #fff;
  }

  canvas {
    display: block;
  }

  /* Banner overlay */
  #banner {
    position: absolute;
    top: 50px;
    left: 50%;
    transform: translateX(-50%);
    width: 90%;
    max-width: 900px;
    background: hsla(0, 0%, 0%, 0);
    padding: 20px;
    border-radius: 15px;
    text-align: center;
    overflow-y: auto;
    max-height: 80%;
    z-index: 2;
  }

  #banner img {
    max-width: 100%;
    border-radius: 10px;
  }

  #banner a {
    color: #1e90ff;
    text-decoration: none;
  }

  #banner a:hover {
    text-decoration: underline;
  }

  h2, h3 {
    margin: 10px 0;
  }

  /* Container for the 3D eye */
  #containerEye {
    position: absolute;
    top: 0;
    left: 0;
    width: 100vw;
    height: 100vh;
    z-index: 1; /* behind banner */
  }
</style>
</head>
<body>

<canvas id="bgCanvas"></canvas>
<div id="containerEye"></div>

<div id="banner">
  <img src="https://github.com/DataWithAnish/DataWithAnish/raw/main/your%20search%20ends%20here.png" alt="Banner Image">

  <h2>üëã Hi there, I‚Äôm Anish Shrestha!</h2>
  <p><a href="https://anishkstha.com.np" target="_blank">anishkstha.com.np</a></p>

  <h3>üöÄ Who Am I?</h3>
  <p>
    I am an international Master‚Äôs student in <strong>Data Science</strong> based in Australia.  
    At my core, I am a <strong>curious learner</strong> and a <strong>problem solver</strong> who enjoys 
    experimenting with <strong>artificial intelligence</strong> and <strong>data-driven solutions</strong>.  
    I have always been fascinated by how raw data can be transformed into knowledge and how machine learning models can
    be used to tackle real-world challenges ‚Äî from identifying plant diseases, to monitoring animal behavior, to making 
    human environments safer.
  </p>
  <p>
    My background spans <strong>data engineering</strong>, <strong>cloud computing</strong>, and <strong>machine learning</strong>.  
    I‚Äôve worked with <strong>ETL pipelines</strong>, <strong>object detection models</strong>, and <strong>statistical analysis</strong>.  
    Currently, I‚Äôm focusing on building <strong>YOLO-powered real-time detection systems</strong> while also exploring 
    deep learning architectures like <strong>CNNs</strong>, <strong>RNNs</strong>, and <strong>Transformers</strong>.
  </p>

  <h3>‚ú® My Interests</h3>
  <p>
    I am deeply passionate about <strong>computer vision</strong>, especially tasks such as object detection, 
    image segmentation, and real-time video analytics.  
    I love the challenge of building models that don‚Äôt just perform well in theory, but also run efficiently in the real world.  
  </p>
  <p>
    Beyond machine learning, I enjoy <strong>data storytelling</strong> ‚Äî turning complex findings into insights that 
    are accessible to everyone. I write blogs about my learning process, tools I experiment with, and the challenges 
    I face while developing AI models. Personally, I enjoy working on <strong>creative side projects</strong> like building browser extensions, experimenting with AR navigation apps, and developing tools that make daily life easier.  
    For me, coding is not just work ‚Äî it‚Äôs a form of expression.
  </p>

  <h3>üìä My GitHub Stats</h3>
  <p>üóìÔ∏è It‚Äôs been <strong>16 awesome days</strong> since I joined GitHub üöÄ</p>
  <div>
    <img src="https://github-readme-stats.vercel.app/api?username=DataWithAnish&show_icons=true" alt="GitHub Stats">
    <img src="https://streak-stats.demolab.com?user=DataWithAnish" alt="GitHub Streak">
  </div>
  <div>
    <img src="https://github-readme-stats.vercel.app/api/top-langs/?username=DataWithAnish&layout=compact" alt="Top Languages">
  </div>

  <h3>üî• Projects I‚Äôve Worked On</h3>
  <p>
    Over the past few years, I‚Äôve worked on projects that blend <strong>AI research</strong> with <strong>real-world applications</strong>.  
    I explored animal behavior through goat detection and analysis using CNN and LSTM models, built snake detection systems for safety monitoring, and designed image segmentation pipelines for better visual understanding.  
    I also experimented with face recognition for identity verification and developed several browser extensions and creative tools for everyday problem-solving. While some of these projects cannot be shared publicly due to data confidentiality, I continue to document and release as much as I can on GitHub and through my blog.  
    For me, every project, no matter the size, carries lessons that shape my growth as a developer.
  </p>

  <h3>üõ†Ô∏è Skills & Tools</h3>
  <p>
    My technical toolkit is centered around <strong>Python</strong>, which I use daily alongside frameworks like <strong>TensorFlow</strong>, <strong>PyTorch</strong>, <strong>OpenCV</strong>, and <strong>scikit-learn</strong>.  
    In the realm of data science, I am fluent with <strong>Pandas</strong>, <strong>NumPy</strong>, <strong>SQL</strong>, and visualization libraries such as <strong>Matplotlib</strong>.  
    My expertise in <strong>computer vision</strong> extends to YOLO, CNNs, RNNs, LSTMs, and transfer learning approaches, while my software development knowledge includes GitHub, Streamlit, Django, and API development.  
    On the cloud side, I have experience with <strong>AWS</strong> and <strong>Google Cloud Platform</strong>, where I‚Äôve worked with S3 storage, scalable deployments, and ETL pipeline design.
  </p>

  <h3>üîó Quick Links</h3>
  <p>
    <a href="https://medium.com/@anishkumar.shrestha07/building-a-plant-disease-detection-system-my-experience-managing-and-developing-with-yolov12-on-01ec31ba1ed6" target="_blank">Medium Blog</a> ‚Ä¢
    <a href="#">Streamlit Demo</a> ‚Ä¢
    <a href="#">Kaggle Dataset</a>
  </p>

  <h3>üéØ Current Focus & Ambitions</h3>
  <p>
    My current focus is on pushing the boundaries of <strong>YOLO-based real-time detection systems</strong>, improving their efficiency and scalability for real-world deployment.  
    I am also diving deeper into designing <strong>end-to-end data science pipelines</strong> and exploring architectures beyond CNNs, including <strong>Transformers</strong> and <strong>GANs</strong>.  
    At the heart of my ambition is the goal to <strong>create AI systems that bring tangible value</strong> ‚Äî whether by improving safety, supporting agriculture, or enabling better human‚Äìcomputer interactions.  
    I firmly believe that AI should be designed not only for performance but for people, ensuring that it positively impacts the world around us.
  </p>

  <h3>‚≠ê Philosophy</h3>
  <p>
    <em>"Documenting ideas today to create solutions tomorrow."</em>  
  </p>
  <p>
    For me, every line of code, every dataset, and every experiment is a step towards creating something meaningful.  
    I am motivated by curiosity, guided by discipline, and driven by the vision of using data and AI to solve problems that matter.  
  </p>
  <p style="font-size: 0.8em; color: #aaa; margin-top: 20px;">
    3D Eye model inspired by <a href="https://github.com/gjmolter/web-3dmodel-threejs" target="_blank" style="color: #1e90ff;">Gabriel Molter</a>
  </p>
</div>


<script src="https://cdn.jsdelivr.net/npm/three@0.153.0/build/three.min.js"></script>
<script>
(() => { // IIFE to isolate scope
  // Starfield setup
  const canvas = document.getElementById('bgCanvas');
  const scene = new THREE.Scene();
  const camera = new THREE.PerspectiveCamera(75, window.innerWidth/window.innerHeight, 0.1, 8000);
  camera.position.z = 800;

  const renderer = new THREE.WebGLRenderer({canvas: canvas, alpha:true});
  renderer.setSize(window.innerWidth, window.innerHeight);

  // Starfield geometry
  const starTexture = new THREE.TextureLoader().load('https://threejs.org/examples/textures/sprites/disc.png');
  const particleCount = 2000;
  const geometry = new THREE.BufferGeometry();
  const positions = [];
  const colors = [];
  const sizes = [];

  for (let i = 0; i < particleCount; i++) {
    positions.push(
        (Math.random()-0.5)*2000, // ‚¨ÖÔ∏è reduced spread
        (Math.random()-0.5)*2000, 
        (Math.random()-0.5)*2000
      );
      const colorRand = Math.random();
      if(colorRand < 0.6) colors.push(1,1,1);
      else if(colorRand < 0.75) colors.push(1, 0.85, 0.5);
      else if(colorRand < 0.85) colors.push(1,0.5,0);
      else colors.push(0.5,0.7,1);
      sizes.push(Math.random()*5 + 1);
  }

  geometry.setAttribute('position', new THREE.Float32BufferAttribute(positions, 3));
  geometry.setAttribute('color', new THREE.Float32BufferAttribute(colors, 3));
  geometry.setAttribute('size', new THREE.Float32BufferAttribute(sizes, 1));

  const material = new THREE.PointsMaterial({
      vertexColors: true,
      size: 4,
      map: starTexture,
      transparent: true,
      blending: THREE.AdditiveBlending,
      depthWrite: false
  });

  const stars = new THREE.Points(geometry, material);
  scene.add(stars);

  // Use unique variable names for mouse
  let starMouseX = 0, starMouseY = 0;
  document.addEventListener('mousemove', e => {
      starMouseX = (e.clientX - window.innerWidth/2)/50;
      starMouseY = (e.clientY - window.innerHeight/2)/50;
  });

  function animateStars() {
      requestAnimationFrame(animateStars);
      stars.rotation.y += 0.001 + starMouseX*0.001;
      stars.rotation.x += 0.001 + starMouseY*0.001;
      renderer.render(scene, camera);
  }
  animateStars();

  window.addEventListener('resize', () => {
      camera.aspect = window.innerWidth/window.innerHeight;
      camera.updateProjectionMatrix();
      renderer.setSize(window.innerWidth, window.innerHeight);
  });
})();
</script>

<script type="module">
  import * as THREE from "https://cdn.skypack.dev/three@0.129.0/build/three.module.js";
  import { GLTFLoader } from "https://cdn.skypack.dev/three@0.129.0/examples/jsm/loaders/GLTFLoader.js";
  
  // Scene
  const sceneEye = new THREE.Scene();
  const cameraEye = new THREE.PerspectiveCamera(75, window.innerWidth/window.innerHeight, 0.1, 2000);
  cameraEye.position.z = 600;
  
  const rendererEye = new THREE.WebGLRenderer({ alpha:true, antialias:true });
  rendererEye.setSize(window.innerWidth, window.innerHeight);
  document.getElementById("containerEye").appendChild(rendererEye.domElement);
  
  let pointerX = window.innerWidth/2, pointerY = window.innerHeight/2;
  let eyeObject;
  
  // Load eye model
  const loader = new GLTFLoader();
  loader.load(
    './eye_free_model_3d_by_oscar_creativo/scene.gltf',
    function(gltf){
      eyeObject = gltf.scene;
      eyeObject.scale.set(0.9, 0.9, 0.9); // smaller eye
      eyeObject.position.set(0, 0, 0);
      sceneEye.add(eyeObject);
      console.log("Eye model loaded:", eyeObject);
    },
    function(xhr){ console.log((xhr.loaded / xhr.total * 100) + '% loaded'); },
    function(err){ console.error(err); }
  );
  
  // Lights
  const topLight = new THREE.DirectionalLight(0xffffff, 1);
  topLight.position.set(500, 500, 500);
  sceneEye.add(topLight);
  
  const ambientLight = new THREE.AmbientLight(0x333333, 1);
  sceneEye.add(ambientLight);
  
  // Animate
  function animateEye(){
    requestAnimationFrame(animateEye);
  
    if(eyeObject){
      // Eye rotates based on pointer position (mouse or touch)
      eyeObject.rotation.y = -3 + pointerX / window.innerWidth * 3;
      eyeObject.rotation.x = -1.2 + pointerY * 2.5 / window.innerHeight;
    }
  
    rendererEye.render(sceneEye, cameraEye);
  }
  animateEye();
  
  // üñ±Ô∏è Desktop mouse tracking
  document.addEventListener("mousemove", (e)=>{
    pointerX = e.clientX;
    pointerY = e.clientY;
  });
  
  // üì± Mobile touch tracking
  document.addEventListener("touchmove", (e)=>{
    const touch = e.touches[0];
    pointerX = touch.clientX;
    pointerY = touch.clientY;
  }, { passive: true });
  
  // Resize
  window.addEventListener('resize', ()=>{
    cameraEye.aspect = window.innerWidth/window.innerHeight;
    cameraEye.updateProjectionMatrix();
    rendererEye.setSize(window.innerWidth, window.innerHeight);
  });
</script>


</body>
</html>
